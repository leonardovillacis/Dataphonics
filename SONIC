def SONIC(DF, TF, speed = 0.4, reverse_data = True, invert_data = False, save_audio = True, save_plot = True, plot_filename = 'plot.png', 
          audio_filename = 'output.wav', xlabel = "Years BP", ylabel = "Values", title = "Data Visualization", high_tone = 650, low_tone = 81.25, invert_yaxis = False, 
          volume_factor = 0.1):
    
    # Data input
    df = DF[0]
    Age = DF[1]
    values = DF[2]
    
    # Select timeframe (e.g., years per sound for visualization)
    timeframe = TF
    
########################################## Smoothing and Interpolation Functions
    def loc_eval(x, b):
        loc_est = 0
        for i in enumerate(b): loc_est += i[1] * (x ** i[0])
        return loc_est

    def loess(xvals, yvals, data, alpha, poly_degree=1):
        all_data = sorted(zip(data[xvals].tolist(), data[yvals].tolist()), key=lambda x: x[0])
        xvals, yvals = zip(*all_data)
        evalDF = pd.DataFrame(columns=['v', 'g'])
        n = len(xvals)
        m = n + 1
        q = int(np.floor(n * alpha) if alpha <= 1.0 else n)
        avg_interval = ((max(xvals) - min(xvals)) / len(xvals))
        v_lb = min(xvals) - (.5 * avg_interval)
        v_ub = (max(xvals) + (.5 * avg_interval))
        v = enumerate(np.linspace(start=v_lb, stop=v_ub, num=m), start=1)
        xcols = [np.ones_like(xvals)]
        for j in range(1, (poly_degree + 1)):
            xcols.append([i ** j for i in xvals])
        X = np.vstack(xcols).T
        for i in v:
            iterpos = i[0]
            iterval = i[1]
            iterdists = sorted([(j, np.abs(j - iterval)) for j in xvals], key=lambda x: x[1])
            _, raw_dists = zip(*iterdists)
            scale_fact = raw_dists[q - 1]
            scaled_dists = [(j[0], (j[1] / scale_fact)) for j in iterdists]
            weights = [(j[0], ((1 - np.abs(j[1] ** 3)) ** 3 if j[1] <= 1 else 0)) for j in scaled_dists]
            _, weights = zip(*sorted(weights, key=lambda x: x[0]))
            _, raw_dists = zip(*sorted(iterdists, key=lambda x: x[0]))
            _, scaled_dists = zip(*sorted(scaled_dists, key=lambda x: x[0]))
            W = np.diag(weights)
            b = np.linalg.inv(X.T @ W @ X) @ (X.T @ W @ yvals)
            local_est = loc_eval(iterval, b)
            iterDF2 = pd.DataFrame({'v': [iterval], 'g': [local_est]})
            evalDF = pd.concat([evalDF, iterDF2])
        evalDF = evalDF[['v', 'g']]
        return evalDF

    def smoothen(df, window1):
        evalDF1 = loess(df.iloc[::, 0].name, df.iloc[::, 1].name, data=df, alpha=window1 / Age.max(), poly_degree=0)
        S1 = evalDF1.g
        A1 = evalDF1.v
        return A1, S1
###############################################################################

    # Interpolation
    AgeS = np.arange(Age.min(), Age.max(), timeframe)
    data_int1 = np.interp(AgeS, Age, values)

    df = pd.DataFrame(data_int1, AgeS)
    df.reset_index(inplace=True)

    # Smoothing
    AgeS2, data_int2 = smoothen(df, timeframe * 4)

    # Rescaling
    if reverse_data:
        int2 = data_int2[::-1]
    else:
        int2 = data_int2
    if invert_data:
        data = int2 * -1
    else:
        data = int2

    min_old = np.min(data)
    max_old = np.max(data)
    min_new = low_tone
    max_new = high_tone
    SD = min_new + ((data - min_old) / (max_old - min_old)) * (max_new - min_new)

    # Parameters for the sine wave
    fs = 44100  # Sampling frequency
    duration = speed  # Duration of each sound in seconds
    Freq = SD  # The frequencies corresponding to the smoothed data
    t = np.linspace(0, duration, int(fs * duration), endpoint=False)

    # Generate audio signals for each frequency
    Audiomaster = []
    
    # Intro sound
    ti = np.linspace(0, 1, int(fs * 1), endpoint=False)
    Audiomaster.append(np.sign(np.sin(2 * np.pi * low_tone * ti)))  # low beep
    Audiomaster.append(np.sign(np.sin(2 * np.pi * high_tone * ti)))  # high beep
    Audiomaster.append(np.zeros(int(fs * 0.6)))

    
    for i in Freq:
        audioP = np.sign(np.sin(2 * np.pi * i * t))  # Generating square wave audio
        Audiomaster.append(audioP)

    # Apply volume reduction to all audio samples
    Audiomaster = [audio * volume_factor for audio in Audiomaster]

    # Visualization (plot the original and interpolated/smoothed data)
    plt.plot(Age, values, '-', label='Original Data', color='gray', alpha=0.5)
    plt.plot(AgeS, data_int1, '-', label='Interpolated Data', color='orange')
    plt.plot(AgeS2, data_int2, 'o', label='Smoothed Data', color='red')
    plt.legend()
    plt.xlabel(xlabel)  # Use the input xlabel (default is "Years")
    plt.ylabel(ylabel)  # Use the input ylabel (default is "Values")
    plt.title(title)  # Use the input title (default is "Data Visualization")
    if invert_yaxis==True:
        plt.gca().invert_yaxis()
    plt.gcf().patch.set_facecolor('white')  # Figure background
    
    # Save plot as an image file
    if save_plot:
        plt.savefig(plot_filename, dpi=400)

    # Save the audio to a file
    if save_audio:
        # Combine all the audio data into one continuous array
        full_audio = np.concatenate(Audiomaster)
        sf.write(audio_filename, full_audio, fs)

    return 'Happy listening!'
